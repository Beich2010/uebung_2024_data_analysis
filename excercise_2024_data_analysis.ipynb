{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEfB-NFtPngw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "___\n",
        "___\n",
        "___\n",
        "\n",
        "\n",
        "# **Datenanalyse & Forecasting Excercise 2024**\n",
        "\n",
        "___\n",
        "___\n",
        "___\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "XGm5xu08Pngx",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **1. Introduction**\n",
        "\n",
        "Welcome to our exercise notebook on data analysis and time series forecasting with sktime! This notebook will explore some tools for analyzing data and further show a small pipline approach to forecast future values. This notebook will provide you with some insights and hands-on experience in working with time series data. Therefore, let's get started and dive into the exciting world of data analysis and time series forecasting!\n",
        "\n",
        "Please note it is mandatory to install all the required software and packages using the guide provided in Ilias before proceeding with this exercise notebook. The guide contains important instructions how to properly set up your environment. This ensures that all the necessary dependencies are installed. Failure to follow the instructions may result in errors or unexpected behavior while working through the notebook.\n",
        "\n",
        "This is an interactive notebook and also includes some work assignments. Typical tasks are adding lines of code, documenting observations. Work orders are always marked in the color <span style=\"color:#A00000\"> **red** </span>. We suggest you work in pairs or small groups so that you can share observations and discuss the tasks together.\n",
        "\n",
        "\n",
        "___\n",
        "\n",
        "## Agenda\n",
        "\n",
        "1. Introduction, Agenda, learning goals and data loading\n",
        "\n",
        "2. Data Analysis\n",
        "\n",
        "3. Forecasting Excercise - Forecasting Pipeline and Steps\n",
        "\n",
        "___\n",
        "\n",
        "\n",
        "##  Learning goals (sorted by chapter)\n",
        "\n",
        "### Learning goals data analysis and time series analysis\n",
        "\n",
        "    - Enumerate different properties of time series e.g. seasonality    \n",
        "    - Analyze energy time series and recognize and evaluate seasonal patterns\n",
        "    - Derive and design appropriate calendrical features by considering seasonality and autocorellation function.\n",
        "\n",
        "\n",
        "### Learning goals machine learning\n",
        "    - Name and evaluate various different steps within a machine learning process.\n",
        "    - Be able to name the advantages of splitting data between training and test data.\n",
        "     \n",
        "\n",
        "___\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSvLWIejUhBx"
      },
      "source": [
        "### Colab Setup\n",
        "Installs all the needed packages in your enviroment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS83ftK0P8HA",
        "outputId": "f8d436c9-1882-4b74-eb07-89fe470c14d1"
      },
      "outputs": [],
      "source": [
        "!pip install pandas;\n",
        "!pip install statsmodels;\n",
        "!pip install numpy;\n",
        "!pip install sktime;\n",
        "!pip install matplotlib;\n",
        "!pip install seaborn;\n",
        "!pip install holidays;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEUJ740zQU8l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://data.open-power-system-data.org/household_data/2020-04-15/household_data_15min_singleindex.csv', date_format='%Y-%m-%dT%H:%M:%SZ', index_col = \"cet_cest_timestamp\", parse_dates=True , sep=',')\n",
        "data.index = pd.to_datetime(data.index, utc=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Tl8UueSVPngy",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "## Data loading and first preprocessing\n",
        "As a basis for the data analysis we need data in the first place. This publically available data set is described here: [Full Dataset Introduction](https://data.open-power-system-data.org/household_data/2020-04-15)\n",
        "\n",
        "Here we have taken only a subset of the data, since we want to deal with only one building. Our choice is the industrial building 3. All the data is scaled in kWh. The building has an installed pv and an energy demand.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPErJmqEPngy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from matplotlib import pylab\n",
        "from pylab import *\n",
        "\n",
        "\n",
        "# Basic configuration to get beautiful pictures\n",
        "pylab.rcParams['figure.figsize'] = (16, 9)\n",
        "\n",
        "# Get the relevant data for this excercise and resample it to hourly resolution to save runtime complexity\n",
        "data[\"demand\"] = data[\"DE_KN_industrial3_grid_import\"].diff(1).resample(\"1h\").mean()\n",
        "data[\"solar\"] = (data[\"DE_KN_industrial3_pv_facade\"].diff(1) + data[\"DE_KN_industrial3_pv_roof\"].diff(1)).resample(\"1h\").mean()\n",
        "\n",
        "# Omit data without values\n",
        "data = data[[\"demand\",\"solar\"]].dropna()\n",
        "# Let the data start with a full day and end with a full day\n",
        "data =  data[(data.index >= pd.to_datetime(\"2016-11-03\",utc=True)) &  (data.index < pd.to_datetime(\"2017-06-04\",utc=True))]\n",
        "data = data.asfreq('1h')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7MtQd5N1Pngy",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **2. Data Analysis**\n",
        "\n",
        "<img src=\"https://imgs.xkcd.com/comics/data_trap.png\" width=\"400\" height=\"400\">\n",
        "\n",
        "[This xkcd comic you can find here](https://xkcd.com/2582/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OQyxCvNHPngy",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Within the data analysis chapter, we will first use simple tools from Pandas to get an overview of the data set.\n",
        "After that, we will make a daily observation of the load and analyse the difference between a weekday and weekend.\n",
        "In the last part we will use more complex tools like autocorellation plots and a seasonal decomposition to identify properties like trend and seasonality in our time series.\n",
        "\n",
        "First of all, we would like to show you three very simple functions that Pandas has ready for you :\n",
        "\n",
        "## Warmup and get familiar with the data\n",
        "\n",
        "1. head() First five rows of the data set. Commonly used as a sanity check to see how the Data is constructed. [API](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)\n",
        "2. describe() Provides basic satistical values of the dataset. For example, mean, standard deviation and quantiles.[API](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)\n",
        "3. plot() The plot function draws a simple plot over all collumns of the given dataset with mathplolib. [API](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)\n",
        "\n",
        "### <span style=\"color:#A00000\"> Use the three functions (head, describe and plot) below! </span>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "kWGre2FpPngy",
        "outputId": "3a096e79-231b-44f2-90a6-dac880d270cb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Use the head function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Sf8WtpXaPngz",
        "outputId": "9234472f-2eaa-4b54-e860-06ef22b7e951",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Use the describe function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "oQs251B2Pngz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Discuss in your group: </span>\n",
        " - <span style=\"color:#A00000 \"> Based on these broad statistic, what would you infer about the house considered? </span>\n",
        " - <span style=\"color:#A00000 \"> Do these statistics help you to get a feel for the data and what it looks like? </span>\n",
        " - <span style=\"color:#A00000 \"> Does this data seem realistic? </span>\n",
        " - <span style=\"color:#A00000 \"> Do you see any challanges? </span>\n",
        " - <span style=\"color:#A00000 \"> How much data do we have? </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vfzoTLVKPngz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "< Space for your answers>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "z-6tKBLHPngz",
        "outputId": "3d9b79d4-89c8-4e86-8650-6600bcd1152d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Use the plot function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "y1-cl3lvPngz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Point out two observations about the given data! </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "LfDFrp0GPngz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "1. < Observation 1 >\n",
        "2. < Observation 2 >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nP26nEwNPngz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Discuss in your group: </span>\n",
        " - <span style=\"color:#A00000 \"> What did you find more beneficial, the statistics of the plots? </span>\n",
        " - <span style=\"color:#A00000 \"> Do you see a benefit in both statstics and plots or would you only consider one of them? </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "9PdIOHhBPngz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "< Space for your answers>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "AtxtwtDjPngz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Daily observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "dJhEo9YlPngz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "This part first shows an example of the pivot table how it is used to plot the data on daily basis. Further it extends by using the month attribute to plot the months in different plots. As you can see differnt days of the month are plotted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "VtrR_4KAPngz",
        "outputId": "9659adcc-c117-4d2f-e55f-1b2d423c939c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Calculating the hour of the day the weekday and the day since the beginning of the time series to create the pivot table\n",
        "data[\"hour\"] = data.index.hour.values\n",
        "data[\"weekday\"] = data.index.weekday.values\n",
        "data[\"month\"] = data.index.month.values\n",
        "data[\"days_since_start\"] = [int(x/(24)) for x in range(0,len(data))]\n",
        "\n",
        "# creates the pivot table to get a table with the days since start in the columns and hours of the day as rows. For later usage the months are taken into account as the value parameter.\n",
        "pivot_solar = pd.pivot_table(data, index=['hour'],columns=['days_since_start'], values=['solar','month'])\n",
        "pivot_solar[\"solar\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "XLCQjNdAPng0",
        "outputId": "3bd2e01e-a681-4d95-8b8f-62e430f2a661",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,len(data[\"month\"].unique()))\n",
        "for i in range(len(data[\"month\"].unique())):\n",
        "    pivot_solar[pivot_solar[\"month\"]==data[\"month\"].unique()[i]][\"solar\"].plot(ax=ax[i],figsize=(30, 4), layout= (7,1),ylim = (0,5),legend=False, colormap=\"summer\", title=\"Month : \" + str(data[\"month\"].unique()[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JcTDdYlAPng0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Discuss in your group: </span>\n",
        " - <span style=\"color:#A00000 \"> What do you observe during the different months ? </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JcFwU8gKPng0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Workingdays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lK1ImjvuPng0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Plot only the working days (i.e. Monday-Friday):</span>\n",
        " - <span style=\"color:#A00000 \">The aim is to first filter the data to only get the days from Monday to Friday.</span>\n",
        " - <span style=\"color:#A00000 \">Create a variable ``working_day_data`` and use the weekday column in ``data`` to select the working days. The weekday column is enumerated from 0-6 with 0 being monday and 6 sunday. Therefore working days are the days with a weekday value smaller than five. You can select a column in pandas with ``data[\"column_name\"]`` and if you want to select a subset of the data based on the value in this column you need to use the syntax ``data[data[\"column_name\"] * x]``, where ``*`` indicates a mathematical operater such as ``<`` and ``x`` is the condition. For example, to only select Tuesday you would use ``tuesday_data = data[data[\"weekday\"] == 1]``.</span>\n",
        " - <span style=\"color:#A00000 \">Create the pivot table similar to the example above using the function pivot_table from pandas! [API](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html). Make sure you use the filtered ``working_day_data`` variable created above.</span>\n",
        " - <span style=\"color:#A00000 \">Extend the pivot table to plot working days. Use \"days_since_start\" as ``columms``, \"hour\" as ``index`` and \"demand\" as ``values``!</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "Tb9YxlhYPng0",
        "outputId": "f6b40092-bddf-4368-ce7c-cb74e01add84",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "working_day_data = ...\n",
        "pivot_workingdays = ...\n",
        "\n",
        "# plots the data\n",
        "pivot_workingdays[\"demand\"].plot(legend=False,colormap=\"summer\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5cRGQHFIPng0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Weekend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "b0aj4SfaPng0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Plot the weekends:</span>\n",
        " - <span style=\"color:#A00000 \">Repeat the task above, but this time only select the weekends (remember weekday is enumerated from 0-6, with 0 being Monday).</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "ouN30jvnPng0",
        "outputId": "d6778929-c08c-4a85-c2bf-57dceaa0b380",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# this get's gapped\n",
        "weekday_data = ...\n",
        "pivot_weekends = ...\n",
        "pivot_weekends[\"demand\"].plot(legend=False,colormap=\"summer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEW6czprPng0",
        "outputId": "7c746f20-4df5-4828-ce00-e1e7b5f32620",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Plot the median of all weekdays\n",
        "#\n",
        "\n",
        "pivot_workingdays.median(axis=1).plot(color=\"red\", label=\"Working Median\")\n",
        "pivot_workingdays.quantile(0.25,axis=1).plot(color=\"red\",linestyle='dotted', label=\"Working 0.25 Quantile\")\n",
        "pivot_workingdays.quantile(0.75,axis=1).plot(color=\"red\",linestyle='dotted', label=\"Working 0.75 Quantile\")\n",
        "pivot_weekends.median(axis=1).plot(color=\"blue\", label=\"Weekend Median\")\n",
        "pivot_weekends.quantile(0.25,axis=1).plot(color=\"blue\",linestyle='dotted', label=\"Weekend 0.25 Quantile\")\n",
        "pivot_weekends.quantile(0.75,axis=1).plot(color=\"blue\",linestyle='dotted', label=\"Weekend 0.75 Quantile\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "DP89G2qKPng0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Discuss in your group:</span>\n",
        " - <span style=\"color:#A00000 \"> Do these different plots (weekdays, weekends, median) fit your expectations?</span>\n",
        " - <span style=\"color:#A00000 \"> What could explain the pattern for this building for a weekday? </span>\n",
        " - <span style=\"color:#A00000 \"> Could you interfer the base load of the building by looking at the daily observation plots? </span>\n",
        " - <span style=\"color:#A00000 \"> How could explain the higher variance of weekdays in contrast to weekends? </span>\n",
        " - <span style=\"color:#A00000 \"> Based on these observations, what features would you consider extracting or engineering for a forecasting task? </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OdqP94K1Png0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "< Space for your answers>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Z-kg_cH_Png0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Autorcorrelation Function and Seasonal Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pILh_UEIPng0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Autocorrelation Function Plot\n",
        "\n",
        "\n",
        "The autocorrelation function (ACF) is a statistical technique that we can use to identify how correlated the values in a time series are with each other. The ACF plots the correlation coefficient against the lag, which is measured in terms of a number of periods or units. [Explanation from here](https://www.baeldung.com/cs/acf-pacf-plots-arma-modeling#:~:text=The%20autocorrelation%20function%20(ACF)%20is,number%20of%20periods%20or%20units.)\n",
        "\n",
        "An detailed expleanation is here: [Autocorrelation](https://support.minitab.com/en-us/minitab/21/help-and-how-to/statistical-modeling/time-series/how-to/autocorrelation/interpret-the-results/autocorrelation-function-acf/)\n",
        "\n",
        "API-Statsmodels [API](https://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.acf.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "eTTu3gKCPng0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Seasonal Decomposition\n",
        "\n",
        "An detailed explaination about the used seasonal decomposition can be found here: [API](https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html)\n",
        "\n",
        "The additive model which is used here is defined as $Y[t] = T[t] + S[t] + e[t]$.\n",
        "\n",
        "The results are obtained by first estimating the trend by applying a convolution filter to the data. The trend is then removed from the series and the average of this de-trended series for each period is the returned seasonal component."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nGznQN2mPng1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### Demand ACF and Seasonal Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kQQxTBF_Png1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Play around with autocorrelation: </span>\n",
        "- <span style=\"color:#A00000 \"> Use the ``sm.tsa.graphics.plot_acf(x, lags=None)`` function to plot the autocorrelation function of ``data[\"demand\"]``. </span>\n",
        "- <span style=\"color:#A00000 \"> Play around with a different number of lags, i.e. 5, 24, 200. </span>\n",
        "- <span style=\"color:#A00000 \"> What do you observe? </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0TcXTeaPng1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CiX-xKfwPng1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        " ### <span style=\"color:#A00000 \"> Play around with seasonal decomposition: </span>\n",
        "- <span style=\"color:#A00000 \"> Use the ``statsmodels.tsa.seasonal.seasonal_decompose(x, period=None)`` function to create a seasonal decomposition of ``data[\"demand\"]``. </span>\n",
        "- <span style=\"color:#A00000 \"> Visualise this decomposition with ``sm.tsa.seasonal_decompose().plot()``. </span>\n",
        "- <span style=\"color:#A00000 \"> Adjust the ''period'' parameter of the function, try for example 24 (a day), or 168 (a week), or something random (e.g. 77). </span>\n",
        "- <span style=\"color:#A00000 \"> What do you observe? </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtQhvQScPng1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# do seasonal decomposition of demand here\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JBLyPMA3Png1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### ACF and Seasonal Decomposition Solar\n",
        "\n",
        " ### <span style=\"color:#A00000 \"> Repeat the above two tasks for the solar data! </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqXHxjouPng1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# do seasonale decomposition on solar data (data[\"solar\"])\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfxPHpKbPng1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# do seasonal decomposition of demand here\n",
        "...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "i6RYgastPng1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# <span style=\"color:#A00000 \">  STOP HERE - We want to discuss some things together before going on </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "hYXQ6TfmPng2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **3. Forecasting Excercise - Forecasting Pipeline and Steps**\n",
        "\n",
        "In this section of the Jupyter Notebook, you will learn about using SkTime to perform time series forecasting. Time series forecasting is a technique used to predict future values of a variable based on historical data and possible known exogenous variables. It can be useful in many fields, such as finance, economics, and engineering, but also in energy informatics.\n",
        "\n",
        "\n",
        "\n",
        "A selection of useful links can be found here:\n",
        "\n",
        "Basic sktime API describtion: [API](https://www.sktime.net/en/stable/)\n",
        "\n",
        "List of Forecasters: [FORECASTERS](https://www.sktime.net/en/stable/estimator_overview.html#filter=all&tags=%7B%7D)\n",
        "\n",
        "Information about Forecasting Horizon: [FH](https://www.sktime.net/en/stable/api_reference/auto_generated/sktime.forecasting.base.ForecastingHorizon.html)\n",
        "\n",
        "Information about ExpandingWindowSplitter: [Splitter](https://www.sktime.net/en/v0.21.0/api_reference/auto_generated/sktime.forecasting.model_selection.ExpandingWindowSplitter.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "PFbyNH6YPng2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Exercises\n",
        "\n",
        "The exercises walk you through the creation of a time series forecast. You will see a very basic sktime workflow producing a time series forecast of the data already known from the previous excercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "SRlydsmpPng2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Now, let's look at what we prepared:\n",
        "\n",
        "### Data\n",
        "We use the data from the previous excercise part.\n",
        "\n",
        "### Metrics\n",
        "\n",
        "To evaluate the accuracy of the forecast, the section provides various metrics, such as mean absolute error and root mean squared error. These metrics allow you to understand how close the forecasted values are to the actual values. Those metrics are introduced here:\n",
        "\n",
        "\n",
        "$ \\text{MAPE} = \\frac{1}{n} \\sum_{t=1}^{n} \\left| \\frac{A_t - F_t}{A_t} \\right| $\n",
        "\n",
        "$ \\text{MAE} = \\frac{1}{n} \\sum_{t=1}^{n} \\left| A_t - F_t \\right| $\n",
        "\n",
        "$ \\text{MSE} = \\frac{1}{n} \\sum_{t=1}^{n} \\left( A_t - F_t \\right)^2 $\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- <span style=\"color:#A00000 \"> What are those Metrics sensitive for?</span>\n",
        "\n",
        "\n",
        "\n",
        "### Models\n",
        "\n",
        "\n",
        "###\n",
        "To help with the interpretation of the results, the section includes visualizations of the forecasted values and actual values over time. These visualizations can help you identify trends and patterns that may not be immediately apparent from the metrics alone.\n",
        "\n",
        "Overall, this section provides a practical introduction to using sktime for time series forecasting. By the end of the section you have understood a basic example for time series forecasting. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sktime.forecasting.naive import NaiveForecaster\n",
        "from sktime.utils.plotting import plot_series\n",
        "from sktime.forecasting.model_evaluation import evaluate\n",
        "from sktime.split import ExpandingWindowSplitter\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sktime.performance_metrics.forecasting import MeanAbsoluteError , MeanSquaredError , MedianAbsolutePercentageError\n",
        "import warnings\n",
        "\n",
        "#\n",
        "# Needed as sktime throws a lot of exceptions\n",
        "#\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "#\n",
        "# Dummy Demonstration How the basic sktime workflow for prediction works within a naive forecaster \n",
        "#\n",
        "\n",
        "# step 1: data specification\n",
        "y = data[\"demand\"][24*4:24*13]\n",
        "# step 2: specifying forecasting horizon\n",
        "fh = np.arange(1, 24)\n",
        "# step 3: specifying the forecasting algorithm\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=24*7)\n",
        "# step 4: fitting the forecaster\n",
        "forecaster.fit(y)\n",
        "# step 5: querying predictions\n",
        "y_pred = forecaster.predict(fh)\n",
        "# optional: plotting predictions and past data\n",
        "plot_series(y, y_pred, labels=[\"y\", \"y_pred\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <span style=\"color:#A00000 \"> Discuss with your group: </span>\n",
        "- <span style=\"color:#A00000 \"> Discuss what the naiv forecaster does? </span>\n",
        "- <span style=\"color:#A00000 \"> Why could a navie forecaster could be useful?</span>\n",
        "- <span style=\"color:#A00000 \"> What is the basic assumption behind a naive forecaster?</span>\n",
        "- <span style=\"color:#A00000 \"> Where a naive forecaster fails and why?</span>\n",
        "- <span style=\"color:#A00000 \"> How can other forecaster prevent this?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv = ExpandingWindowSplitter(\n",
        "    step_length=24, fh=[i for i in range(1,25)], initial_window=100*24\n",
        ")\n",
        "\n",
        "metrics = [MedianAbsolutePercentageError(), MeanAbsoluteError(), MeanSquaredError()]\n",
        "\n",
        "y = data[\"demand\"]\n",
        "\n",
        "\n",
        "#\n",
        "#   NaiveForecaster\n",
        "#\n",
        "\n",
        "forecaster = ...\n",
        "df_naive = evaluate(forecaster=forecaster, y=y, cv=cv, return_data=True,scoring=metrics)\n",
        "\n",
        "\n",
        "#\n",
        "#   KNeighborsRegressor\n",
        "#  \n",
        "\n",
        "regressor = ...\n",
        "forecaster = make_reduction(regressor, window_length=24*7, strategy=\"direct\")\n",
        "df_knr = evaluate(forecaster=forecaster, y=y, cv=cv,return_data=True, strategy=\"refit\",scoring=metrics)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization of a forecaster evaluation\n",
        "\n",
        "day = 1\n",
        "\n",
        "fig, ax = plot_series(\n",
        "    y.iloc[24*100+(24*(day-1)):24*100+24*day],\n",
        "    df_naive[\"y_pred\"].iloc[day-1],\n",
        "    df_knr[\"y_pred\"].iloc[day-1],\n",
        "    labels=[\"y\", \"Naive\", \"KNR\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation Block using the different metrics\n",
        "\n",
        "loss_cols = [\"test_MedianAbsolutePercentageError\",\"test_MeanAbsoluteError\",\"test_MeanSquaredError\"]\n",
        "\n",
        "# generate a dataframe containing the results\n",
        "\n",
        "df_results = pd.DataFrame(columns=[\"Model\",\"MAPE\",\"MAE\",\"MSE\"])\n",
        "\n",
        "# add all forecasters in a list with thier results\n",
        "\n",
        "df_results_naiv = pd.DataFrame({\"Model\":\"Naive\",\"MAPE\":df_naive[\"test_MedianAbsolutePercentageError\"].mean(),\"MAE\":df_naive[\"test_MeanAbsoluteError\"].mean(),\"MSE\":df_naive[\"test_MeanSquaredError\"].mean()},index=[0])\n",
        "df_results_knr = pd.DataFrame({\"Model\":\"KNR\",\"MAPE\":df_knr[\"test_MedianAbsolutePercentageError\"].mean(),\"MAE\":df_knr[\"test_MeanAbsoluteError\"].mean(),\"MSE\":df_knr[\"test_MeanSquaredError\"].mean()},index=[0])\n",
        "\n",
        "df_results = pd.concat([df_results,df_results_naiv,df_results_knr])\n",
        "\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enrich the forecast with features\n",
        "\n",
        "Information about the features can be found [here](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.transformations.series.date.DateTimeFeatures.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sktime.transformations.series.date import DateTimeFeatures\n",
        "from sktime.transformations.series.holiday import HolidayFeatures\n",
        "from holidays import country_holidays\n",
        "\n",
        "holiday_transformer = HolidayFeatures(\n",
        "   calendar=country_holidays(country=\"DE\",state=\"BW\"),\n",
        "   include_bridge_days=True\n",
        "   )  \n",
        "X_holiday = holiday_transformer.fit_transform(y)\n",
        "X_holiday[\"holiday\"] = X_holiday.sum(axis=1)\n",
        "\n",
        "\n",
        "\n",
        "calendar_transformer = DateTimeFeatures(ts_freq=\"H\", manual_selection=[\"day_of_week\", \"hour_of_day\"])\n",
        "X_calendar = calendar_transformer.fit_transform(y)\n",
        "\n",
        "#join them together as a feature matrix\n",
        "\n",
        "X = pd.concat([X_holiday[\"holiday\"], X_calendar], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#\n",
        "#   KNeighborsRegressor\n",
        "#  \n",
        "\n",
        "regressor = ...\n",
        "forecaster = make_reduction(regressor, window_length=24*7, strategy=\"direct\")\n",
        "df_knr_features = evaluate(forecaster=forecaster,y=y,X=X,cv=cv,return_data=True, strategy=\"refit\",scoring=metrics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualization of a forecaster evaluation\n",
        "\n",
        "day = 1\n",
        "\n",
        "fig, ax = plot_series(\n",
        "    y.iloc[24*100+(24*(day-1)):24*100+24*day],\n",
        "    df_naive[\"y_pred\"].iloc[day-1],\n",
        "    df_knr[\"y_pred\"].iloc[day-1],\n",
        "    df_knr_features[\"y_pred\"].iloc[day-1],\n",
        "    labels=[\"y\", \"Naive\", \"KNR\", \"KNR Features\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation Block using the different metrics\n",
        "\n",
        "loss_cols = [\"test_MedianAbsolutePercentageError\",\"test_MeanAbsoluteError\",\"test_MeanSquaredError\"]\n",
        "\n",
        "# generate a dataframe containing the results\n",
        "\n",
        "df_results = pd.DataFrame(columns=[\"Model\",\"MAPE\",\"MAE\",\"MSE\"])\n",
        "\n",
        "# add all forecasters in a list with thier results\n",
        "\n",
        "df_results_naiv = pd.DataFrame({\"Model\":\"Naive\",\"MAPE\":df_naive[\"test_MedianAbsolutePercentageError\"].mean(),\"MAE\":df_naive[\"test_MeanAbsoluteError\"].mean(),\"MSE\":df_naive[\"test_MeanSquaredError\"].mean()},index=[0])\n",
        "df_results_knr = pd.DataFrame({\"Model\":\"KNR\",\"MAPE\":df_knr[\"test_MedianAbsolutePercentageError\"].mean(),\"MAE\":df_knr[\"test_MeanAbsoluteError\"].mean(),\"MSE\":df_knr[\"test_MeanSquaredError\"].mean()},index=[0])\n",
        "df_results_knr_features = pd.DataFrame({\"Model\":\"KNR Features\",\"MAPE\":df_knr_features[\"test_MedianAbsolutePercentageError\"].mean(),\"MAE\":df_knr_features[\"test_MeanAbsoluteError\"].mean(),\"MSE\":df_knr_features[\"test_MeanSquaredError\"].mean()},index=[0])\n",
        "\n",
        "df_results = pd.concat([df_results,df_results_naiv,df_results_knr,df_results_knr_features])\n",
        "\n",
        "df_results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cFV2G3yxPng3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Now we are going to visualise the data..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "PC00eqnLPng3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## <span style=\"color:#A00000 \"> Now you can play! </span>\n",
        "- <span style=\"color:#A00000 \"> Play around with the forecast horizon and the number of historical features.</span>\n",
        "- <span style=\"color:#A00000 \"> You can also try altering the scope variable being forecast.</span>\n",
        "- <span style=\"color:#A00000 \"> How do the results change?</span>\n",
        "- <span style=\"color:#A00000 \"> Which forecasters perform best?</span>\n",
        "- <span style=\"color:#A00000 \"> How quantity is the easiest to forecast?</span>\n",
        "<span style=\"color:#A00000 \">Feel free to spend time discussing the results in your group and if you have questions don't hesitate to ask!</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "aVPqBLy0Png3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<img src=\"https://imgs.xkcd.com/comics/machine_learning.png\" width=\"600\" height=\"800\">\n",
        "\n",
        "[This xkcd comic you can find here](https://xkcd.com/1838/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
